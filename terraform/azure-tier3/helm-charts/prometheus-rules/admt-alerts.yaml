# Custom Prometheus Alert Rules for ADMT Migration
# Deploy with: kubectl apply -f admt-alerts.yaml

apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: admt-migration-alerts
  namespace: monitoring
  labels:
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
    - name: admt.migration
      interval: 30s
      rules:
        # Critical: Migration failure rate too high
        - alert: HighMigrationFailureRate
          expr: |
            (
              sum(rate(awx_job_failed_total{job_template=~".*migration.*"}[5m]))
              /
              sum(rate(awx_job_total{job_template=~".*migration.*"}[5m]))
            ) > 0.10
          for: 5m
          labels:
            severity: critical
            component: migration
          annotations:
            summary: "High migration failure rate detected"
            description: "Migration failure rate is {{ $value | humanizePercentage }}. More than 10% of migrations are failing."
            runbook_url: "https://github.com/yourusername/auto-domain-migration/wiki/HighMigrationFailureRate"
        
        # Warning: Elevated migration failure rate
        - alert: ElevatedMigrationFailureRate
          expr: |
            (
              sum(rate(awx_job_failed_total{job_template=~".*migration.*"}[5m]))
              /
              sum(rate(awx_job_total{job_template=~".*migration.*"}[5m]))
            ) > 0.05
          for: 10m
          labels:
            severity: warning
            component: migration
          annotations:
            summary: "Elevated migration failure rate"
            description: "Migration failure rate is {{ $value | humanizePercentage }}. Investigate potential issues."
        
        # Critical: No migrations running during business hours
        - alert: NoMigrationsRunning
          expr: |
            (
              sum(rate(awx_job_total{job_template=~".*migration.*"}[10m])) == 0
            )
            and
            (
              hour() >= 9 and hour() <= 17
            )
            and
            (
              day_of_week() >= 1 and day_of_week() <= 5
            )
          for: 2h
          labels:
            severity: warning
            component: migration
          annotations:
            summary: "No migrations running during business hours"
            description: "No migration jobs have run in the last 2 hours during business hours (9 AM - 5 PM, Mon-Fri)."
        
        # Critical: Domain controller unreachable
        - alert: DomainControllerUnreachable
          expr: |
            up{job="domain-controllers"} == 0
          for: 2m
          labels:
            severity: critical
            component: infrastructure
          annotations:
            summary: "Domain controller {{ $labels.instance }} is unreachable"
            description: "Domain controller at {{ $labels.instance }} has been unreachable for 2 minutes."
        
        # Warning: Slow migration performance
        - alert: SlowMigrationPerformance
          expr: |
            histogram_quantile(0.95,
              sum(rate(awx_job_elapsed_seconds_bucket{job_template=~".*migration.*"}[5m])) by (le)
            ) > 600
          for: 15m
          labels:
            severity: warning
            component: migration
          annotations:
            summary: "Migration performance is degraded"
            description: "95th percentile migration time is {{ $value | humanizeDuration }}. Expected <10 minutes."
        
        # Critical: Batch migration stuck
        - alert: MigrationJobStuck
          expr: |
            time() - awx_job_start_time{status="running", job_template=~".*migration.*"} > 3600
          for: 5m
          labels:
            severity: critical
            component: migration
          annotations:
            summary: "Migration job {{ $labels.job_name }} appears stuck"
            description: "Migration job has been running for over 1 hour without completion."
    
    - name: admt.fileserver
      interval: 30s
      rules:
        # Warning: Low file transfer speed
        - alert: LowFileTransferSpeed
          expr: |
            rate(minio_s3_requests_incoming_bytes[1m]) / 1024 / 1024 < 10
          for: 5m
          labels:
            severity: warning
            component: fileserver
          annotations:
            summary: "File transfer speed is low"
            description: "Transfer speed is {{ $value | humanize }} MB/s. Expected >10 MB/s."
        
        # Critical: Very low file transfer speed
        - alert: VeryLowFileTransferSpeed
          expr: |
            rate(minio_s3_requests_incoming_bytes[1m]) / 1024 / 1024 < 1
          for: 10m
          labels:
            severity: critical
            component: fileserver
          annotations:
            summary: "File transfer speed is critically low"
            description: "Transfer speed is {{ $value | humanize }} MB/s. Investigation required."
        
        # Warning: Storage capacity warning
        - alert: StorageCapacityWarning
          expr: |
            (
              minio_bucket_usage_object_total
              /
              minio_cluster_capacity_usable_total_bytes
            ) > 0.80
          for: 10m
          labels:
            severity: warning
            component: fileserver
          annotations:
            summary: "Storage capacity above 80%"
            description: "Bucket {{ $labels.bucket }} is {{ $value | humanizePercentage }} full."
        
        # Critical: Storage capacity critical
        - alert: StorageCapacityCritical
          expr: |
            (
              minio_bucket_usage_object_total
              /
              minio_cluster_capacity_usable_total_bytes
            ) > 0.90
          for: 5m
          labels:
            severity: critical
            component: fileserver
          annotations:
            summary: "Storage capacity above 90%"
            description: "Bucket {{ $labels.bucket }} is {{ $value | humanizePercentage }} full. Add capacity immediately."
        
        # Critical: File server unavailable
        - alert: FileServerUnavailable
          expr: |
            up{job="minio"} == 0
          for: 2m
          labels:
            severity: critical
            component: fileserver
          annotations:
            summary: "MinIO server {{ $labels.instance }} is down"
            description: "File server at {{ $labels.instance }} has been down for 2 minutes."
        
        # Warning: High file transfer error rate
        - alert: HighFileTransferErrorRate
          expr: |
            rate(minio_s3_requests_errors_total[5m]) > 10
          for: 5m
          labels:
            severity: warning
            component: fileserver
          annotations:
            summary: "High file transfer error rate"
            description: "Error rate is {{ $value }} errors/second on {{ $labels.instance }}."
    
    - name: admt.database
      interval: 30s
      rules:
        # Warning: High database connection usage
        - alert: HighDatabaseConnectionUsage
          expr: |
            pg_stat_database_numbackends{datname="awx"} / 300 > 0.80
          for: 5m
          labels:
            severity: warning
            component: database
          annotations:
            summary: "Database connection pool above 80%"
            description: "{{ $value }} connections active out of 300 maximum."
        
        # Critical: Database connection pool exhausted
        - alert: DatabaseConnectionPoolExhausted
          expr: |
            pg_stat_database_numbackends{datname="awx"} > 290
          for: 2m
          labels:
            severity: critical
            component: database
          annotations:
            summary: "Database connection pool near exhaustion"
            description: "{{ $value }} connections active out of 300. Add connection capacity or investigate connection leaks."
        
        # Warning: High replication lag
        - alert: HighReplicationLag
          expr: |
            pg_replication_lag_seconds > 30
          for: 5m
          labels:
            severity: warning
            component: database
          annotations:
            summary: "PostgreSQL replication lag is high"
            description: "Replication lag is {{ $value | humanizeDuration }} on {{ $labels.instance }}."
        
        # Critical: Database unavailable
        - alert: DatabaseUnavailable
          expr: |
            up{job="postgresql"} == 0
          for: 1m
          labels:
            severity: critical
            component: database
          annotations:
            summary: "PostgreSQL database is unavailable"
            description: "Database at {{ $labels.instance }} has been down for 1 minute."
        
        # Warning: Slow queries
        - alert: SlowDatabaseQueries
          expr: |
            rate(pg_stat_statements_mean_time_seconds[5m]) > 1
          for: 10m
          labels:
            severity: warning
            component: database
          annotations:
            summary: "Slow database queries detected"
            description: "Average query time is {{ $value | humanizeDuration }}. Investigate query performance."
    
    - name: admt.infrastructure
      interval: 30s
      rules:
        # Warning: Pod restarting frequently
        - alert: PodRestartingFrequently
          expr: |
            rate(kube_pod_container_status_restarts_total{namespace=~"automation|data|security"}[1h]) > 5
          for: 5m
          labels:
            severity: warning
            component: infrastructure
          annotations:
            summary: "Pod {{ $labels.pod }} is restarting frequently"
            description: "Pod has restarted {{ $value }} times in the last hour."
        
        # Critical: Pod in CrashLoopBackOff
        - alert: PodCrashLooping
          expr: |
            kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", namespace=~"automation|data|security"} > 0
          for: 5m
          labels:
            severity: critical
            component: infrastructure
          annotations:
            summary: "Pod {{ $labels.pod }} is crash looping"
            description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is in CrashLoopBackOff state."
        
        # Warning: Node CPU high
        - alert: NodeCPUHigh
          expr: |
            (1 - avg by (node) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) > 0.80
          for: 10m
          labels:
            severity: warning
            component: infrastructure
          annotations:
            summary: "Node {{ $labels.node }} CPU usage is high"
            description: "CPU usage is {{ $value | humanizePercentage }} on node {{ $labels.node }}."
        
        # Critical: Node CPU critical
        - alert: NodeCPUCritical
          expr: |
            (1 - avg by (node) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) > 0.90
          for: 5m
          labels:
            severity: critical
            component: infrastructure
          annotations:
            summary: "Node {{ $labels.node }} CPU usage is critical"
            description: "CPU usage is {{ $value | humanizePercentage }} on node {{ $labels.node }}. Scale up cluster."
        
        # Warning: Node memory high
        - alert: NodeMemoryHigh
          expr: |
            (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.85
          for: 10m
          labels:
            severity: warning
            component: infrastructure
          annotations:
            summary: "Node {{ $labels.node }} memory usage is high"
            description: "Memory usage is {{ $value | humanizePercentage }} on node {{ $labels.node }}."
        
        # Critical: PVC almost full
        - alert: PersistentVolumeAlmostFull
          expr: |
            (kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes) > 0.85
          for: 10m
          labels:
            severity: warning
            component: infrastructure
          annotations:
            summary: "PVC {{ $labels.persistentvolumeclaim }} is {{ $value | humanizePercentage }} full"
            description: "PVC in namespace {{ $labels.namespace }} is running out of space."

